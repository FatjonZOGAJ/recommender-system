\documentclass[10pt,conference,compsocconf]{IEEEtran}

%\usepackage{times}
%\usepackage{balance}
\usepackage{url, amsmath, amssymb}
\usepackage{graphicx}    % For figure environment
\usepackage{textcomp}
\usepackage{amsfonts}

\newcommand{\spacing}{\hspace{1cm}}
\begin{document}
    \title{Collaborative Filtering}

    \author{
    Filip Batur\spacing Patrik Okanovic\spacing Rafael Sterzinger\spacing Fatjon Zogaj\\
    Group: Terminators\\
    ETH Zurich, Switzerland
    }

    \maketitle

    \begin{abstract}

    \end{abstract}


    \section{Introduction}
    %TODO write generally about collaborative filtering/recommender system
    We look at the task of Collaborative Filtering which is a technique widely used in recommender systems.
    Recommender systems primarily aim at enabling customers to find items of potential interest.
    Some possible usages of this are movie recommendations on Netflix, 'Made for you' playlists on spotify or 'Other people also bought' ads on Amazon.
    Collaborative Filtering makes use of existing knowledge of the general user body and combines this with the specific user information regarding other items to present him/her new recommendations.
    %TODO write about related problem of netflix price and movielense
    %TODO Maybe take a look into "On the difficulta on evaluating Baselines" -> old proposed methods perform surprisingly well, also as information on general methods
    %TODO general mathmatical formulation of the problem, maybe see past reports

    For this problem constellation our dataset consists of rating from 10,000 users on 1,000 movies.
    We note that not every user (or any for that matter) has rated every movie.
    With 1,176,952 rating we have a sparsity level of around 12 percent.
    This information is of further importance as many models and techniques depend on the initialization of non-observed techniques.



    \section{Related Work}
    %TODO might not be necessary only for text filler if needed


    \section{Models and Methods}
    In the following section we describe the different methods we used combined with our baseline models and our final best model.

    %TODO mention papers with code and the used baselines from there and from the collab notebook
    %TODO Maybe take a look into "On the difficulta on evaluating Baselines"

    %TODO add clipping techniques, initialization of missing values, and if done de-biasing

    \subsection{Singular Value Decomposition}

    \subsection{Non-Negative Matrix Factorization}

    \subsection{Autoencoder}
    An autoencoder is a neural network that is trained to attempt to copy its input to its output.
    Internally, it has a hidden layer $\textbf{h} \in \mathbb{R}^k$ that describes a code used to represent the input.
    The network may be viewed as consisting of two parts: an encoder function $f: \mathbb{R} ^d \rightarrow \mathbb{R} ^k$ and a
    decoder that produces a reconstruction $g: \mathbb{R} ^k \rightarrow \mathbb{R} ^d$ \cite{Goodfellow-et-al-2016}. Autoencoders
    have proven to achieve good results in collaborative filtering \cite{inproceedings}. We examine the user-based
    autoencoder as opposed to item-based autoencoder which achieved a good score in \cite{inproceedings}. Both encoder
    and decoder consist of feedforward neural networks with ReLU activation functions. We train the model by minimizing
    the squared reconstruction loss. Important part of the implementation is the fact that inputs are partially observed
    and therefore we only update those weights that are associated with observed inputs during backpropagation.
    We found that when both encoder and decoder consist of one layer increasing the encoded dimension up to 500 makes
    the score better. Furthermore, we have examined the effect of compositionality. Using only two layers in encoder
    and decoder already performs better than any single layer autoencoder.

    \subsection{Neural Collaborative Filtering}
    Neural Collaborative Filtering approach as proposed by He et al. \cite{DBLP:journals/corr/abs-1708-05031}, tries to
    jointly learn user-item latent representations as well as the prediction depending on the interactions between
    different users and items. The network's inputs are indices of users and items. Firstly, an embedding layer maps
    each user and each item to its corresponding latent vector representation. Output of the embedding layers is then
    concatenated and passed on through fully connected feedforward layers with ReLU activation functions. Finally,
    output of the network represents the rating associated with the inputted user and item. Network is trained minimizing
    the mean squared error loss between the predicted and target rating. TODO: erase? Further, improvements would be
    implementing the network as a classification task between the movie rating rather then regressing the predicted rating.

    \subsection{Kernel Net}

    \subsection{Bayesian Factorization Machines}
    For our final baseline, we explored Bayesian Factorization Machines \textbf{(BFM)} which are Bayesian variants of the former known Factorization Machines \textbf{(FM)} \cite{rendle_factorization_2010}.
    In its core, FMs build upon the advantages of Support Vector Machines \textbf{(SVM)} but use a factorized parametrization instead of a dense one.
    With this parametrization, FMs are able to estimate all possible interactions between entries of $\mathbf{X}$ even in setting where the data matrix $\mathbf{X}$ is highly sparse.
    Similarly to SVMs with a polynomial kernel, the FM model equation which captures all single and pairwise interactions, can be formulated as follows:

    $$\hat{y}(\mathbf{x})=w_0+\sum^n_{i=1}w_ix_i + \sum^n_{i=1}\sum^n_{j=i+1}\langle \mathbf{v_i},\mathbf{v_j} \rangle x_ix_j$$

    Here, $v_i$ denotes a vector in $\mathbb{R}^k$ which describes the $i$-th variable with $k$ dimensions and $\langle \mathbf{v_i},\mathbf{v_j} \rangle$ the interaction between the variables $i$ and $j$.
    Instead of using a fixed weight $w_{ij}$, this factorization via the dot product allows FMs to predict parameters for related interaction, e.g. different users but same movie.
    In the non-Bayesian setting, model parameters are optimized with stochastic gradient descent.
    Opposed to this are Bayesian variants of FMs where model parameters are estimated via maximum a posteriori estimation by means of Markov Chain Monte Carlo methods for approximate inference \cite{salakhutdinov_bayesian_2008}.
    This fully Bayesian treatment of FMs does not only increase the accuracy of such a model but also omits the need of exhaustive parameter tuning \cite{freudenthaler_bayesian_2011}.
    Regarding, the implementation of our baseline, we utilize a package named \textit{myFM} \cite{noauthor_myfm_nodate} which employs Gibbs sampling for approximate inference of the posterior.
    Besides this standard variant of BFMs, multiple additions have been made by means of exploiting additional implicit information about users, items, and temporal dynamics \cite{rendle_scaling_2013,koren_factorization_2008,koren_collaborative_2009}.
    In our implementation, we incorporated most of these as well, omitting temporal dynamics due to the absence of this information in our provided dataset.
    The two additional features are defined as follows:
    \begin{enumerate}
        \item Implicit User Feature (Bayesian SVD++) $\Leftrightarrow$ all items consumed by user $u$:
        $$\mathbf{V}_u=\frac{\Omega_u}{\sqrt{|\{(u,i): (u,i) \in \Omega_u\}|}}$$
        \item Implicit Item Feature (Bayesian SVD++ flipped) $\Leftrightarrow$ all users that consumed item $i$:
        $$\mathbf{W}_i=\frac{\Omega^T_i}{\sqrt{|\{(u,i): (u,i) \in \Omega^T_i\}|}}$$
    \end{enumerate}
    After one-hot-encoding users $\mathbf{U}$ and items $\mathbf{I}$, denoted as the identity matrix $I_k$ with corresponding dimension $k$, a single entry in our dataset would have the following form:
    $$\mathbf{x}_{ui} = [(I_n)_u,\mathbf{V}_u,(I_m)_i,\mathbf{W}_i, r_{ui}]$$

    Additionally, datasets commonly used in the setting of collaborative filtering such as the MovieLens dataset include much more detailed information on users/items.
    In the setting of movie recommendations, for instance, the genre or the release date of a movie, a timestamp of when the user gave the rating, or user specific information such as who is friends with whom might be included.
    As we found that these details might be greatly beneficial for our prediction task, we created features which resemble the previously mentioned ones based on the limited data we were provided.
    Here, we concentrated mainly on two aspects, calculating the similarity between users to imitate the "friends of a user" feature, and clustering a movie embedding space to create a "movie genre" feature.

    \subsubsection{User Features}
    Regarding the additional user features in the form of similarity measures between two users, we looked at different variants of the Jaccard index, the standard variant and an improved version of it \cite{lee_improving_2017}.
    The standard Jaccard index measures the similarity between two users u and v as follows:
    $$\text{Jac}(u,v)=\frac{|\mathbf{I}_u \cap \mathbf{I}_v|}{|\mathbf{I}_u \cup \mathbf{I}_v|}$$
    Furthermore, we experimented with an improved version of the Jaccard index.
    Here, the set of items $\mathbf{I}_u$ a user $u$ has consumed is subdivided into three parts $L,M,$ and $H$ with two boundaries $L_{bd}$ and $H_{bd}$.
    Given these boundaries the sets are formulated as follows:
    \begin{align*}
          &\mathbf{I}_{L,u}=\{i \in \mathbf{I}_u : r_{u,i} \leq L_{bd}\}\\
          &\mathbf{I}_{M,u}=\{i \in \mathbf{I}_u : L_{bd} < r_{u,i} < H_{bd}\}\\
          &\mathbf{I}_{H,u}=\{i \in \mathbf{I}_u : H_{bd} \leq r_{u,i}\}\\
    \end{align*}
    The improved Jaccard index with these definied subsets is denoted as follows:
    $$\text{Jac}_{LMH}=\frac{1}{3}(\text{Jac}_L(u,v) + \text{Jac}_M(u,v) + \text{Jac}_H(u,v))$$
    According to the authors the bound $L_{bd} = 3$ and $H_{bd}=4$ yielded the best results on the MovieLens dataset.
    As such, we set the same bounds, effectively splitting into two instead of three sets.

    \subsubsection{Movie Features}
    In order to provide additional information for models, we implement clustering and that way simulate the information
    about movie categories as in the MovieLens Dataset TODO: CITE. First we initialize the matrix using FM:TODO.
    Afterwards, we perform Singular Value Decomposition with the rank that showed best results (TODO ref the plot).
    We get the embeddings using the following expression: assuming $A=U\Sigma V^T$ then the matrix corresponding to the movie embeddings is equal to $\Sigma _k ^{\frac{1}{2}} V_k ^T$.
    Finally, after obtaining the k-rank movie embeddings we search for the optimal number of clusters in K-Means clustering.
    We visualize the clusters in 2 dimensions. Since, visualizing in two dimensions does not easily distinct the optimal
    number of clusters we choose 18 as in the MovieLens dataset as the number of clusters. Figure \ref{movie_category_distribution}
    shows two peaks in movie categories while other categories look uniformly distributed.

    \begin{figure}
        \label{movie_category_distribution}
        \includegraphics[width=\columnwidth]{figures/movie_category_distribution.png}
        \caption{Distribution of movie categories between 18 categories as in MovieLens dataset.}
    \end{figure}

    With these additional user/item features, we append to our feature vector $\mathbf{x}_{ui}$ a dense vector of user similarities from user $u$ to every other user, or the item feature which is either the one-hot-encoded cluster of item $i$ or a dense vector of Euclidean/Mahalanobis distances from item $i$ to every other item.

    %TODO write about ordered probtis

    \subsubsection{Iterative SVD}

    \subsubsection{Ensembles}


    \section{Results and Discussion}
    %TODO importance of shuffeling


    \subsection{Comparison to Baselines}

    You compare your novel algorithm to \emph{at least two baseline
    algorithms}. For the baselines, you can use the implementations you
    developed as part of the programming assignments.


    \section{Conclusion}

    Organize the results section based on the sequence of table and
    figures you include. Prepare the tables and figures as soon as all
    the data are analyzed and arrange them in the sequence that best
    presents your findings in a logical way. A good strategy is to note,
    on a draft of each table or figure, the one or two key results you
    want to address in the text portion of the results.
    The information from the figures is
    summarized in Table.




    \bibliographystyle{IEEEtran}
    \bibliography{bibliography}
\end{document}
