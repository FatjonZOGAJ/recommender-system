
@article{rendle_difficulty_2019,
	title = {On the Difficulty of Evaluating Baselines: A Study on Recommender Systems},
	url = {http://arxiv.org/abs/1905.01395},
	shorttitle = {On the Difficulty of Evaluating Baselines},
	abstract = {Numerical evaluations with comparisons to baselines play a central role when judging research in recommender systems. In this paper, we show that running baselines properly is diﬃcult. We demonstrate this issue on two extensively studied datasets. First, we show that results for baselines that have been used in numerous publications over the past ﬁve years for the Movielens 10M benchmark are suboptimal. With a careful setup of a vanilla matrix factorization baseline, we are not only able to improve upon the reported results for this baseline but even outperform the reported results of any newly proposed method. Secondly, we recap the tremendous eﬀort that was required by the community to obtain high quality results for simple methods on the Netﬂix Prize. Our results indicate that empirical ﬁndings in research papers are questionable unless they were obtained on standardized benchmarks where baselines have been tuned extensively by the research community.},
	journaltitle = {{arXiv}:1905.01395 [cs]},
	author = {Rendle, Steffen and Zhang, Li and Koren, Yehuda},
	urldate = {2021-07-25},
	date = {2019-05-03},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1905.01395},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning},
	file = {Rendle et al. - 2019 - On the Difficulty of Evaluating Baselines A Study.pdf:/home/rafael/Zotero/storage/4QYHBZLQ/Rendle et al. - 2019 - On the Difficulty of Evaluating Baselines A Study.pdf:application/pdf}
}

@inproceedings{lee_improving_2017,
	title = {Improving Jaccard Index for Measuring Similarity in Collaborative Filtering},
	isbn = {978-981-10-4153-2},
	doi = {10.1007/978-981-10-4154-9_93},
	abstract = {In collaborative filtering-based recommender systems, items are recommended by consulting ratings of similar users. However, if the number of ratings to compute similarity is not sufficient, the system may produce unreliable recommendations. Since this data sparsity problem is critical in collaborative filtering, many researchers have made efforts to develop new similarity metrics taking care of this problem. Jaccard index has also been a useful tool when combined with existing similarity measures to handle data sparsity problem. This paper proposes a novel improvement of Jaccard index that reflects the frequency of ratings assigned by users as well as the number of items co-rated by users. Performance of the proposed index is evaluated through extensive experiments to find that the proposed significantly outperforms Jaccard index especially in a dense dataset and that its combination with a previous similarity measure is superior to existing measures in terms of both prediction and recommendation qualities.},
	pages = {799--806},
	author = {Lee, Soojung},
	date = {2017-03-18},
	file = {Full Text PDF:/home/rafael/Zotero/storage/QRITN8UG/Lee - 2017 - Improving Jaccard Index for Measuring Similarity i.pdf:application/pdf}
}

@inproceedings{salakhutdinov_bayesian_2008,
	location = {Helsinki, Finland},
	title = {Bayesian probabilistic matrix factorization using Markov chain Monte Carlo},
	isbn = {978-1-60558-205-4},
	url = {http://portal.acm.org/citation.cfm?doid=1390156.1390267},
	doi = {10.1145/1390156.1390267},
	abstract = {Low-rank matrix approximation methods provide one of the simplest and most eﬀective approaches to collaborative ﬁltering. Such models are usually ﬁtted to data by ﬁnding a {MAP} estimate of the model parameters, a procedure that can be performed eﬃciently even on very large datasets. However, unless the regularization parameters are tuned carefully, this approach is prone to overﬁtting because it ﬁnds a single point estimate of the parameters. In this paper we present a fully Bayesian treatment of the Probabilistic Matrix Factorization ({PMF}) model in which model capacity is controlled automatically by integrating over all model parameters and hyperparameters. We show that Bayesian {PMF} models can be eﬃciently trained using Markov chain Monte Carlo methods by applying them to the Netﬂix dataset, which consists of over 100 million movie ratings. The resulting models achieve signiﬁcantly higher prediction accuracy than {PMF} models trained using {MAP} estimation.},
	eventtitle = {the 25th international conference},
	pages = {880--887},
	booktitle = {Proceedings of the 25th international conference on Machine learning - {ICML} '08},
	publisher = {{ACM} Press},
	author = {Salakhutdinov, Ruslan and Mnih, Andriy},
	urldate = {2021-07-25},
	date = {2008},
	langid = {english},
	file = {Salakhutdinov and Mnih - 2008 - Bayesian probabilistic matrix factorization using .pdf:/home/rafael/Zotero/storage/HHEUYTAC/Salakhutdinov and Mnih - 2008 - Bayesian probabilistic matrix factorization using .pdf:application/pdf}
}

@misc{freudenthaler_bayesian_nodate,
	title = {Bayesian Factorization Machines},
	abstract = {This work presents simple and fast structured Bayesian learning for matrix and tensor factorization models. An unblocked Gibbs sampler is proposed for factorization machines ({FM}) which are a general class of latent variable models subsuming matrix, tensor and many other factorization models. We empirically show on the large Netflix challenge dataset that Bayesian {FM} are fast, scalable and more accurate than state-of-the-art factorization models. 1},
	author = {Freudenthaler, Christoph and Schmidt-thieme, Lars and Rendle, Steffen},
	file = {Citeseer - Snapshot:/home/rafael/Zotero/storage/K69Z32EF/summary.html:text/html;Citeseer - Full Text PDF:/home/rafael/Zotero/storage/E7PRI6DB/Freudenthaler et al. - Bayesian Factorization Machines.pdf:application/pdf}
}

@article{rendle_scaling_2013,
	title = {Scaling factorization machines to relational data},
	volume = {6},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/2535573.2488340},
	doi = {10.14778/2535573.2488340},
	abstract = {The most common approach in predictive modeling is to describe cases with feature vectors (aka design matrix). Many machine learning methods such as linear regression or support vector machines rely on this representation. However, when the underlying data has strong relational patterns, especially relations with high cardinality, the design matrix can get very large which can make learning and prediction slow or even infeasible.},
	pages = {337--348},
	number = {5},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	shortjournal = {Proc. {VLDB} Endow.},
	author = {Rendle, Steffen},
	urldate = {2021-07-25},
	date = {2013-03},
	langid = {english},
	file = {Rendle - 2013 - Scaling factorization machines to relational data.pdf:/home/rafael/Zotero/storage/CD59HCYY/Rendle - 2013 - Scaling factorization machines to relational data.pdf:application/pdf}
}

@article{koren_collaborative_nodate,
	title = {Collaborative Filtering with Temporal Dynamics},
	abstract = {Customer preferences for products are drifting over time. Product perception and popularity are constantly changing as new selection emerges. Similarly, customer inclinations are evolving, leading them to ever redeﬁne their taste. Thus, modeling temporal dynamics should be a key when designing recommender systems or general customer preference models. However, this raises unique challenges. Within the eco-system intersecting multiple products and customers, many different characteristics are shifting simultaneously, while many of them inﬂuence each other and often those shifts are delicate and associated with a few data instances. This distinguishes the problem from concept drift explorations, where mostly a single concept is tracked. Classical time-window or instancedecay approaches cannot work, as they lose too much signal when discarding data instances. A more sensitive approach is required, which can make better distinctions between transient effects and long term patterns. The paradigm we offer is creating a model tracking the time changing behavior throughout the life span of the data. This allows us to exploit the relevant components of all data instances, while discarding only what is modeled as being irrelevant. Accordingly, we revamp two leading collaborative ﬁltering recommendation approaches. Evaluation is made on a large movie rating dataset by Netﬂix. Results are encouraging and better than those previously reported on this dataset.},
	pages = {9},
	author = {Koren, Yehuda},
	langid = {english},
	file = {Koren - Collaborative Filtering with Temporal Dynamics.pdf:/home/rafael/Zotero/storage/FIP957SU/Koren - Collaborative Filtering with Temporal Dynamics.pdf:application/pdf}
}

@article{koren_factorization_nodate,
	title = {Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model},
	abstract = {Recommender systems provide users with personalized suggestions for products or services. These systems often rely on Collaborating Filtering ({CF}), where past transactions are analyzed in order to establish connections between users and products. The two more successful approaches to {CF} are latent factor models, which directly proﬁle both users and products, and neighborhood models, which analyze similarities between products or users. In this work we introduce some innovations to both approaches. The factor and neighborhood models can now be smoothly merged, thereby building a more accurate combined model. Further accuracy improvements are achieved by extending the models to exploit both explicit and implicit feedback by the users. The methods are tested on the Netﬂix data. Results are better than those previously published on that dataset. In addition, we suggest a new evaluation metric, which highlights the differences among methods, based on their performance at a top-K recommendation task.},
	pages = {9},
	author = {Koren, Yehuda},
	langid = {english},
	file = {Koren - Factorization Meets the Neighborhood a Multifacet.pdf:/home/rafael/Zotero/storage/6BMWU7DF/Koren - Factorization Meets the Neighborhood a Multifacet.pdf:application/pdf}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{DBLP:journals/corr/abs-1708-05031,
  author    = {Xiangnan He and
               Lizi Liao and
               Hanwang Zhang and
               Liqiang Nie and
               Xia Hu and
               Tat{-}Seng Chua},
  title     = {Neural Collaborative Filtering},
  journal   = {CoRR},
  volume    = {abs/1708.05031},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.05031},
  archivePrefix = {arXiv},
  eprint    = {1708.05031},
  timestamp = {Mon, 13 Aug 2018 16:49:05 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1708-05031.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{inproceedings,
author = {Sedhain, Suvash and Menon, Aditya and Sanner, Scott and Xie, Lexing},
year = {2015},
month = {05},
pages = {111-112},
title = {AutoRec: Autoencoders Meet Collaborative Filtering},
doi = {10.1145/2740908.2742726}
}
